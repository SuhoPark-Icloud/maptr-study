"""
`MapTR` ëª¨ë¸ì˜ í•™ìŠµì„ ìœ„í•œ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
ë°ì´í„°ì…‹ ë¡œë“œ, ëª¨ë¸ ë° ì†ì‹¤ í•¨ìˆ˜ ì´ˆê¸°í™”, í•™ìŠµ ë£¨í”„ ì‹¤í–‰, ì²´í¬í¬ì¸íŠ¸ ì €ì¥,
TensorBoard ë¡œê¹… ë“±ì˜ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import os

# MPS Fallback ì„¤ì • (í•„ìˆ˜)
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.optim as optim
from nuscenes.nuscenes import NuScenes
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# Custom modules (src í´ë”ì— ìˆëŠ” ê²ƒë“¤)
from src.datasets.dataset import MapTRDataset
from src.models.detectors.maptr import MapTR
from src.models.losses.loss import MapLoss
from src.models.losses.matcher import MapMatcher


# --- 1. Custom Collate Function ---
def maptr_collate_fn(batch):
    """
    `DataLoader`ë¥¼ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ `collate` í•¨ìˆ˜ì…ë‹ˆë‹¤.
    ë°°ì¹˜ ë‚´ì˜ ê°€ë³€ì ì¸ ê¸¸ì´ì˜ ë²¡í„° ë°ì´í„°ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜í•˜ê³ ,
    GT(Ground Truth) ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        batch (list[dict]): ë°ì´í„°ì…‹ì—ì„œ ë¡œë“œëœ ìƒ˜í”Œë“¤ì˜ ë¦¬ìŠ¤íŠ¸.

    Returns:
        tuple: ì´ë¯¸ì§€, ì„¼ì„œ-ì°¨ëŸ‰ ë³€í™˜ í–‰ë ¬, ë‚´ë¶€ íŒŒë¼ë¯¸í„°, íƒ€ê²Ÿ í…ì„œë“¤ì˜ íŠœí”Œ.
    """
    imgs = torch.stack([item["imgs"] for item in batch])
    intrinsics = torch.stack([item["intrinsics"] for item in batch])
    sensor2egos = torch.stack([item["sensor2egos"] for item in batch])

    targets = []
    for item in batch:
        labels = []
        points = []
        for cls_name, pts in item["vectors"]:
            # í´ë˜ìŠ¤ ë§¤í•‘: divider->0, ped_crossing->1, boundary->2
            if cls_name == "divider":
                l = 0
            elif cls_name == "ped_crossing":
                l = 1
            else:
                l = 2
            labels.append(l)
            points.append(pts)

        if len(labels) > 0:
            targets.append(
                {
                    "labels": torch.tensor(labels, dtype=torch.long),
                    "points": torch.stack(points),  # [N, 20, 2]
                }
            )
        else:
            targets.append(
                {
                    "labels": torch.empty(0, dtype=torch.long),
                    "points": torch.empty(0, 20, 2),
                }
            )

    return imgs, sensor2egos, intrinsics, targets


# --- 2. TensorBoard Visualization Function ---
def visualize_for_tensorboard(writer, epoch, step, outputs, targets):
    """
    ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼(BEV ë§µ)ì™€ ì •ë‹µ(Ground Truth)ì„ ì‹œê°í™”í•˜ì—¬
    TensorBoardì— ì´ë¯¸ì§€ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        writer (SummaryWriter): TensorBoard ë¡œê±° ê°ì²´.
        epoch (int): í˜„ì¬ ì—í­.
        step (int): í˜„ì¬ ê¸€ë¡œë²Œ ìŠ¤í….
        outputs (dict): ëª¨ë¸ì˜ ì˜ˆì¸¡ ì¶œë ¥.
        targets (list[dict]): ì •ë‹µ íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸.
    """
    # ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ë°ì´í„°ë§Œ ê°€ì ¸ì˜´ (CPUë¡œ ì´ë™)
    pred_logits = outputs["pred_logits"][0].detach().cpu()  # [Q, 3]
    pred_points = outputs["pred_points"][0].detach().cpu()  # [Q, P, 2]

    # GTê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
    if len(targets) > 0:
        gt_points = targets[0]["points"].detach().cpu()  # [N, P, 2]
    else:
        gt_points = torch.empty(0)

    # ì ìˆ˜ ê³„ì‚°
    scores = pred_logits.sigmoid()
    max_scores, _ = scores.max(dim=-1)

    # Figure ìƒì„±
    fig, ax = plt.subplots(figsize=(10, 10))

    # ì¶• ì„¤ì • (Forward=Up)
    swap_axis = True

    # A. Ground Truth ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰)
    if gt_points.numel() > 0:
        for i in range(len(gt_points)):
            pts_norm = gt_points[i].numpy()
            pts_meter = np.copy(pts_norm)

            # Denormalize
            # X (ì „í›„): 0~1 -> -30~30 (Range 60)
            real_x = pts_meter[:, 0] * 60.0 - 30.0
            # Y (ì¢Œìš°): 0~1 -> -15~15 (Range 30)
            real_y = pts_meter[:, 1] * 30.0 - 15.0

            if swap_axis:
                # (Lateral, Forward) -> ì§€ë„ì²˜ëŸ¼ ë³´ê¸°
                ax.plot(real_y, real_x, "g-", linewidth=2, alpha=0.7)
            else:
                ax.plot(real_x, real_y, "g-", linewidth=2, alpha=0.7)

    # B. Prediction ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
    # í•™ìŠµ ì´ˆê¸°ì—ëŠ” ì ìˆ˜ê°€ ë‚®ìœ¼ë¯€ë¡œ 0.1 ì´ìƒì´ë©´ ê·¸ë¦¼
    threshold = 0.1
    for i in range(len(pred_points)):
        if max_scores[i] > threshold:
            pts_norm = pred_points[i].numpy()
            pts_meter = np.copy(pts_norm)

            # Denormalize
            real_x = pts_meter[:, 0] * 60.0 - 30.0
            real_y = pts_meter[:, 1] * 30.0 - 15.0

            if swap_axis:
                ax.plot(real_y, real_x, "r-", linewidth=2)
            else:
                ax.plot(real_x, real_y, "r-", linewidth=2)

    ax.grid(True)
    ax.set_aspect("equal")

    if swap_axis:
        ax.set_xlim(-15, 15)  # ì¢Œìš° 15m
        ax.set_ylim(-30, 30)  # ì „í›„ 30m
        ax.set_title(f"Epoch {epoch} Step {step} (Green: GT, Red: Pred)")
        ax.axvline(x=0, color="k", linestyle="--", alpha=0.3)
        ax.axhline(y=0, color="k", linestyle="--", alpha=0.3)
    else:
        ax.set_xlim(-30, 30)
        ax.set_ylim(-15, 15)

    # TensorBoardì— ê¸°ë¡
    writer.add_figure("Prediction/BEV_Map", fig, global_step=step)
    plt.close(fig)  # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€


# --- 3. Main Training Loop ---
def main():
    """
    ë©”ì¸ í•™ìŠµ í•¨ìˆ˜ì…ë‹ˆë‹¤. ì „ì²´ í•™ìŠµ ê³¼ì •ì„ ì„¤ì •í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    1. í•™ìŠµ ì¥ì¹˜(device), TensorBoard ë¡œê±°, ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    2. ëª¨ë¸, ë§¤ì²˜, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    3. ì²´í¬í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ í•™ìŠµì„ ì¬ê°œí•˜ê³ , ì—†ìœ¼ë©´ ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.
    4. ì§€ì •ëœ ì—í­ ìˆ˜ë§Œí¼ í•™ìŠµ ë£¨í”„ë¥¼ ì‹¤í–‰í•˜ë©°, ì†ì‹¤ ê³„ì‚°, ì—­ì „íŒŒ, íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    5. ì£¼ê¸°ì ìœ¼ë¡œ TensorBoardì— ì†ì‹¤ ê°’ê³¼ ì‹œê°í™” ê²°ê³¼ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
    6. ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    """
    # 1. Setup
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"ğŸš€ Training on {device}...")

    # TensorBoard Writer ì´ˆê¸°í™” (logs/maptr_exp í´ë”ì— ì €ì¥)
    writer = SummaryWriter(log_dir="logs/maptr_exp")

    dataroot = os.path.join(os.getcwd(), "data", "nuscenes")
    nusc = NuScenes(version="v1.0-mini", dataroot=dataroot, verbose=False)
    dataset = MapTRDataset(nusc, is_train=True)

    # [ë©”ëª¨ë¦¬ ìµœì í™”] ë°°ì¹˜ ì‚¬ì´ì¦ˆ 2 ì„¤ì •
    dataloader = DataLoader(
        dataset, batch_size=2, shuffle=True, collate_fn=maptr_collate_fn
    )
    print(f"âœ… Total Batch Count: {len(dataloader)}")

    # 2. Model & Loss Init
    model = MapTR(num_classes=3).to(device)
    matcher = MapMatcher(cost_class=2.0, cost_point=5.0)
    criterion = MapLoss(num_classes=3, matcher=matcher).to(device)
    optimizer = optim.AdamW(model.parameters(), lr=6e-4, weight_decay=0.01)

    # 3. Resume Configuration
    num_epochs = 100
    save_dir = "./checkpoints"
    os.makedirs(save_dir, exist_ok=True)

    start_epoch = 0
    # ì´ì–´í•  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸° (ìµœì‹ ìˆœ)
    if os.path.exists(os.path.join(save_dir, "maptr_epoch_100.pth")):
        resume_path = os.path.join(save_dir, "maptr_epoch_100.pth")
    elif os.path.exists(os.path.join(save_dir, "maptr_epoch_10.pth")):
        resume_path = os.path.join(save_dir, "maptr_epoch_10.pth")
    else:
        resume_path = None

    if resume_path:
        print(f"ğŸ”„ Resuming training from {resume_path}...")
        try:
            checkpoint = torch.load(resume_path, map_location=device)
            model.load_state_dict(checkpoint["model_state_dict"])
            start_epoch = checkpoint["epoch"] + 1
            print(f"   -> Starting from Epoch {start_epoch + 1}")
        except RuntimeError as e:
            print(f"âš ï¸ Checkpoint load failed (Shape mismatch?): {e}")
            print("ğŸ†• Starting from scratch due to architecture change.")
            resume_path = None
    else:
        print("ğŸ†• No checkpoint found. Starting training from scratch.")

    model.train()
    print("ğŸ Start Training Loop...")

    global_step = start_epoch * len(dataloader)

    for epoch in range(start_epoch, num_epochs):
        total_loss = 0
        for batch_idx, (imgs, sensor2egos, intrinsics, targets) in enumerate(
            dataloader
        ):
            # Data to Device
            imgs = imgs.to(device)
            sensor2egos = sensor2egos.to(device)
            intrinsics = intrinsics.to(device)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            # Forward
            outputs = model(imgs, sensor2egos, intrinsics)

            # Loss Calculation
            loss_dict = criterion(outputs, targets)
            losses = sum(
                loss_dict[k] * criterion.weight_dict[k] for k in loss_dict.keys()
            )

            # Backward
            optimizer.zero_grad()
            losses.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=35)
            optimizer.step()

            # TensorBoard Logging (Scalar)
            writer.add_scalar("Loss/Total", losses.item(), global_step)
            writer.add_scalar("Loss/Class", loss_dict["loss_ce"].item(), global_step)
            writer.add_scalar("Loss/BBox", loss_dict["loss_bbox"].item(), global_step)

            total_loss += losses.item()

            # [ì‹œê°í™”] 10 Step ë§ˆë‹¤ ìˆ˜í–‰ (ë°°ì¹˜2 ê¸°ì¤€ ìì£¼ ì—…ë°ì´íŠ¸ë¨)
            if global_step % 10 == 0:
                visualize_for_tensorboard(writer, epoch, global_step, outputs, targets)

            # Console Logging (10 Step ë§ˆë‹¤)
            if batch_idx % 10 == 0:
                print(
                    f"   Epoch [{epoch + 1}/{num_epochs}] Step [{batch_idx}] "
                    f"Total: {losses.item():.4f}"
                )

            global_step += 1

        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch + 1} Complete. Avg Loss: {avg_loss:.4f}")

        # Checkpoint ì €ì¥ (5 ì—í­ë§ˆë‹¤)
        if (epoch + 1) % 5 == 0 or (epoch + 1) == num_epochs:
            save_path = os.path.join(save_dir, f"maptr_epoch_{epoch + 1}.pth")
            torch.save(
                {
                    "epoch": epoch,
                    "model_state_dict": model.state_dict(),
                    "optimizer_state_dict": optimizer.state_dict(),
                    "loss": avg_loss,
                },
                save_path,
            )
            print(f"ğŸ’¾ Model saved to {save_path}")

    writer.close()


if __name__ == "__main__":
    main()
